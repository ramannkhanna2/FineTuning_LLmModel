{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e6CTeeHcdoZ",
        "outputId": "094bcc1e-e129-413c-8cb5-d387d2eca160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.11.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.5/375.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.5 (from gradientai)\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, pydantic, gradientai\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.0\n",
            "    Uninstalling pydantic-2.7.0:\n",
            "      Successfully uninstalled pydantic-2.7.0\n",
            "Successfully installed aenum-3.1.15 gradientai-1.11.0 pydantic-1.10.15\n"
          ]
        }
      ],
      "source": [
        "# https://app.gradient.ai/workspace/86d19539-a026-4209-8caa-5274e3555ec1_workspace/fine-tuning/create\n",
        "# run in colab\n",
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select base model as nous-hermes2 model to finetune on gradient ai UI\n",
        "import os\n",
        "os.environ['GRADIENT_WORKSPACE_ID']='86d19539-a026-4209-8caa-5274e3555ec1_workspace'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN']='11uxUIdM47Xgj4YA5QnGd5110KJl9qWO'"
      ],
      "metadata": {
        "id": "SU3cUwwacjww"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"MyModel1\"\n",
        "    )\n",
        "\n",
        "    sample_query = \"### Instruction: Who is APJ Abdul Kalam ? \\n\\n ### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated: {completion}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG3gQ8t9Pmll",
        "outputId": "c4983ddf-2e33-4052-c06d-93fe0af11ea7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asking: ### Instruction: Who is APJ Abdul Kalam ? \n",
            "\n",
            " ### Response:\n",
            "Generated: APJ Abdul Kalam was the 11th President of India, serving from 2002 to 2007. He was a renowned scientist and aerospace engineer, widely known as the \"Missile Man of India\" for his significant contributions to India's civilian space program and military missile development. Kalam was a recipient of several prestigious awards, including the Bharat Ratna, India's highest civilian honor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.gradient.ai/docs/sdk-tutorial\n",
        "\n",
        "from gradientai import Gradient\n",
        "\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"MyModel1\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "\n",
        "    sample_query = \"### Instruction: Who is Raman Khanna? \\n\\n ### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "    ## Before Finetuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(before fine tuning): {completion}\")\n",
        "\n",
        "    samples=[\n",
        "        {\"inputs\":\"### Instruction: Who is Raman Khanna? \\n\\n### Response: Raman is a AI consultant who consults on Data Science,AI And LLM \"},\n",
        "        {\"inputs\":\"### Instruction: Who is this person named ? \\n\\n### Response: Raman Khanna Like Data Science And AI \"},\n",
        "        {\"inputs\":\"### Instruction: What do you know about Raman Khanna? \\n\\n### Response: Raman is a AI consultant who consults on Data Science,AI And LLM\"},\n",
        "        {\"inputs\":\"### Instruction: Can you tell me about Raman Khanna? \\n\\n### Response: Raman Khanna is a trainer,administrator,who loves Data Science And AI and LLM's\"}\n",
        "    ]\n",
        "\n",
        "    ## Lets define parameters for finetuning\n",
        "    num_epochs=3\n",
        "    count=0\n",
        "    while count<num_epochs:\n",
        "      print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "      new_model_adapter.fine_tune(samples=samples)\n",
        "      count=count+1\n",
        "\n",
        "    #after fine tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(after fine tuning): {completion}\")\n",
        "\n",
        "\n",
        "    sample_query2 = \"### Instruction: What is Raman's favourite subject and whats the favourite topic he wants to study ? \\n\\n ### Response:\"\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(f\"Asking: {sample_query2}\")\n",
        "\n",
        "    completion = new_model_adapter.complete(query=sample_query2, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated: {completion}\")\n",
        "\n",
        "    new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U5D6rx6deHY",
        "outputId": "927ff799-e420-4421-bde6-d50758f7cd2b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 7c1c7737-e0d5-4560-b479-bbdcce81a493_model_adapter\n",
            "Asking: ### Instruction: Who is Raman Khanna? \n",
            "\n",
            " ### Response:\n",
            "Generated(before fine tuning):  Raman Kahana is a fictional character in the television series \"The Flash\". He is the son of Iris West and Barry Allen, and is also known as the \"Future Flash\". Raman is a speedster and a member of Team Flash, using his abilities to help protect Central City from various threats.\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "Generated(after fine tuning):  Raman is a AI consultant who consults on Data Science,AI And LLM 3 And Instruction Follower 0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Asking: ### Instruction: What is Raman's favourite subject and whats the favourite topic he wants to study ? \n",
            "\n",
            " ### Response:\n",
            "Generated:  Raman's favorite subject is Mathematics and his favorite topic he wants to study is Graph Theory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pbi2rWAiNARG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}